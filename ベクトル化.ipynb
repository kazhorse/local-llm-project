{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13c324-5b87-4e50-8ed0-1eba1605b1e6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル: text-embedding-mxbai-embed-large-v1\n",
      "総チャンク数: 12239（batch=64）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [42:16<00:00, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 集計 ---\n",
      "embeddings shape: (12239, 1024)\n",
      "平均: 13.208 秒 / バッチ\n",
      "最小: 2.133 秒, 最大: 17.043 秒\n",
      "総処理時間: 2536.02 秒\n",
      "L2正規化: ON（cosine用）\n",
      "\n",
      "保存しました: index/text-embedding-mxbai-embed-large-v1/embeddings.npy\n",
      "保存しました: index/text-embedding-mxbai-embed-large-v1/chunks.parquet\n",
      "保存しました: index/text-embedding-mxbai-embed-large-v1/meta.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# OpenAI互換クライアント\n",
    "from openai import OpenAI\n",
    "\n",
    "# ========= 設定 =========\n",
    "BASE_URL = \"http://localhost:1234/v1\"  # LM Studio Local Server\n",
    "API_KEY  = \"lm-studio\"                # 何でもOK\n",
    "MODEL_ID = \"text-embedding-mxbai-embed-large-v1\"  # ★スクショのAPI identifier\n",
    "\n",
    "INPUT_CSV = \"コマンド推論用_1000_chunked.csv\"\n",
    "TEXT_COL  = \"chunk_text\"\n",
    "\n",
    "INDEX_ROOT = Path(\"index\")            # ここ配下にモデル別フォルダを作る\n",
    "BATCH_SIZE = 64                       # 重い/落ちるなら 16/32\n",
    "SLEEP_SEC  = 0.0                      # 混むなら 0.02~0.1\n",
    "NORMALIZE_L2 = True                   # cosine検索するなら True 推奨\n",
    "# =======================\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"[^\\w\\-\\.]+\", \"_\", s)  # 記号を _ に\n",
    "    s = re.sub(r\"_+\", \"_\", s)\n",
    "    return s\n",
    "\n",
    "def l2_normalize(mat: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    norms = np.linalg.norm(mat, axis=1, keepdims=True)\n",
    "    return mat / np.maximum(norms, eps)\n",
    "\n",
    "def embed_with_lmstudio(texts, client: OpenAI, model: str, batch_size: int = 64):\n",
    "    all_vecs = []\n",
    "    times = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "\n",
    "        t0 = time.time()\n",
    "        resp = client.embeddings.create(model=model, input=batch)\n",
    "        elapsed = time.time() - t0\n",
    "\n",
    "        # 入力順に返る\n",
    "        vecs = [np.array(d.embedding, dtype=np.float32) for d in resp.data]\n",
    "        all_vecs.extend(vecs)\n",
    "        times.append(elapsed)\n",
    "\n",
    "        if SLEEP_SEC:\n",
    "            time.sleep(SLEEP_SEC)\n",
    "\n",
    "    embs = np.stack(all_vecs)  # (N, dim)\n",
    "    return embs, times\n",
    "\n",
    "# ========= 実行 =========\n",
    "df_chunks = pd.read_csv(INPUT_CSV)\n",
    "assert TEXT_COL in df_chunks.columns, f\"{TEXT_COL} 列が見つかりません: {list(df_chunks.columns)}\"\n",
    "\n",
    "texts = df_chunks[TEXT_COL].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "client = OpenAI(base_url=BASE_URL, api_key=API_KEY)\n",
    "\n",
    "print(f\"モデル: {MODEL_ID}\")\n",
    "print(f\"総チャンク数: {len(texts)}（batch={BATCH_SIZE}）\")\n",
    "\n",
    "embs, times = embed_with_lmstudio(texts, client, MODEL_ID, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"\\n--- 集計 ---\")\n",
    "print(f\"embeddings shape: {embs.shape}\")\n",
    "print(f\"平均: {np.mean(times):.3f} 秒 / バッチ\")\n",
    "print(f\"最小: {np.min(times):.3f} 秒, 最大: {np.max(times):.3f} 秒\")\n",
    "print(f\"総処理時間: {np.sum(times):.2f} 秒\")\n",
    "\n",
    "if NORMALIZE_L2:\n",
    "    embs = l2_normalize(embs).astype(np.float32)\n",
    "    print(\"L2正規化: ON（cosine用）\")\n",
    "\n",
    "# ========= 保存（モデル別フォルダ） =========\n",
    "model_dir = INDEX_ROOT / slugify(MODEL_ID)\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "emb_path = model_dir / \"embeddings.npy\"\n",
    "chunks_path = model_dir / \"chunks.parquet\"\n",
    "meta_path = model_dir / \"meta.txt\"\n",
    "\n",
    "np.save(emb_path, embs)\n",
    "df_chunks.to_parquet(chunks_path, index=False)\n",
    "\n",
    "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"model_id={MODEL_ID}\\n\")\n",
    "    f.write(f\"input_csv={INPUT_CSV}\\n\")\n",
    "    f.write(f\"text_col={TEXT_COL}\\n\")\n",
    "    f.write(f\"batch_size={BATCH_SIZE}\\n\")\n",
    "    f.write(f\"normalize_l2={NORMALIZE_L2}\\n\")\n",
    "    f.write(f\"num_chunks={len(texts)}\\n\")\n",
    "    f.write(f\"dim={embs.shape[1]}\\n\")\n",
    "\n",
    "print(f\"\\n保存しました: {emb_path}\")\n",
    "print(f\"保存しました: {chunks_path}\")\n",
    "print(f\"保存しました: {meta_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
